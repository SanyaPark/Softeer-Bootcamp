# 🔥 M1: Spark 마스터 노드에서 pi.py 실행하기

## 과제에서 요구하는 핵심 사항은
✅ 입력 데이터를 읽고
✅ π를 추정하는 계산을 수행한 후
✅ CSV 또는 Parquet으로 결과를 저장하는 것
✅ 이를 spark-submit을 사용하여 실행하는 것

## 1️⃣ "지정된 출력 경로"란?
Spark 자체적으로 "지정된 출력 경로" 가 정해져 있는 것은 아님.
즉, 내가 직접 `save()` 함수를 이용해 특정 경로를 지정해야 함.
일반적으로 **HDFS, S3, 또는 로컬 파일 시스템**의 경로를 지정할 수 있음.

예를 들어,<br>
로컬 디렉토리에 저장 → `"file:///home/sparkuser/output/pi_result.csv"`
HDFS에 저장 → `"hdfs:///user/spark/output/pi_result.csv"`
S3에 저장 → `"s3://my-bucket/output/pi_result.csv"`
Spark는 기본적으로 HDFS 또는 로컬 파일 시스템을 지원함.
이번 미션에서는 **로컬 디렉토리에 저장**하는 방식`(file://)` 으로 실행!

## 2️⃣ `pi.py` 코드 수정 (CSV 저장 기능 추가)

+ RDD 대신 DataFrame을 사용해 `pi_estimate` 값을 저장 가능하게 함.
+ CSV로 저장 (`df.write.csv(output_path)`)
+ 출력 경로를 `file:///home/sparkuser/output/pi_result.csv`로 지정

## 3️⃣ spark-submit 실행 스크립트 작성
🔹 작성된 `spark-submit.sh` (`/home/sparkuser/spark-submit.sh`)
```bash
#!/bin/bash

# Spark 애플리케이션 실행
$SPARK_HOME/bin/spark-submit \
    --master spark://spark-master:7077 \
    --deploy-mode client \
    --executor-memory 1G \
    --total-executor-cores 2 \
    /home/sparkuser/pi.py
```

✅ 코드 설명
* --master spark://spark-master:7077 → Spark Standalone 클러스터의 마스터 URL
* --deploy-mode client → 로컬에서 실행
* --executor-memory 1G → 실행할 때 1GB 메모리 할당
* --total-executor-cores 2 → 2개의 실행 코어 사용
* /home/sparkuser/pi.py → 실행할 Python 코드


## 4️⃣ 실행 방법
1️⃣ spark-submit.sh에 실행 권한을 부여
```bash
chmod +x /home/sparkuser/spark-submit.sh
```
2️⃣ 실행
```bash
/home/sparkuser/spark-submit.sh
```

---
## Trials and Errors
### Spark가 CSV 파일 대신 폴더를 생성하는 이유!
Spark의 `df.write.csv("경로")` 방식은 단일 파일이 아니라 여러 개의 파티션 파일을 포함하는 폴더를 생성하는 구조.
👉 즉, Spark는 `pi_result.csv`라는 폴더를 만들고 그 안에 여러 개의 CSV 파일을 저장한 것.

📌 이렇게 만들어진 폴더 내부에 있는 파일들 설명:
`_SUCCESS` → Spark 작업이 정상적으로 완료되었음을 나타내는 빈 파일
`.crc` 파일들 → HDFS(혹은 로컬 파일 시스템)의 데이터 무결성 체크용

### 단일 CSV 파일로 저장하는 방법
Spark에서 단일 파일로 저장하려면 `.coalesce(1)`을 사용!
``` python
    # ✅ 단일 CSV 파일로 저장
    df.coalesce(1).write.mode("overwrite").option("header", "true").csv(output_dir)

    # ✅ 생성된 CSV 파일을 `pi_result.csv`로 이동
    # import glob
    csv_file = glob.glob(f"{output_dir}/*.csv")[0]  # CSV 파일 찾기
    os.rename(csv_file, output_file)  # 파일명 변경
```

`--master` 플래그는 접속할 클러스터의 주소를 지정해 주는데, 여기서 쓴 `spark://URL`은 스파크의 단독 모드를 사용한 클러스터를 의미한다.

`spark://host:port`
> 스파크 단독 클러스터의 지정한 포트로 접속한다. 기본적으로 스파크 단독 마스터들은 7077 포트를 쓴다.

`yarn`
> 얀 클러스터에 접속한다. YARN에서 실행할 때는 클러스터 정보를 갖고 있는 하둡 설정 디렉토리를 HADOOP_CONF_DIR 환경 변수에 설정해 주어야 한다.
